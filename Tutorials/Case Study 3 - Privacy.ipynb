{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "97e2d93c",
   "metadata": {},
   "source": [
    "# Case Study 3 - Privacy\n",
    "These notebooks are also available on Google Colab. This enables you to run the notebooks without having to set up an environment locally and gives you access to GPUs to run the notebooks on.\n",
    " \n",
    "[![Run in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1JOstMJmhI2wcufyBqZ1iV3YqOdThJ-_U?usp=sharing#scrollTo=05sK9fusnBp8)\n",
    "\n",
    "## 1. Introduction\n",
    "Machine learning (ML) is empowering more and more communities by using their historical datasets. Unfortunately, some sectors and use cases have been precluded from the benefits of ML, due to the requirement of their data to remain private. In this case study we will look at methods that aim to solve this problem by creating synthetic datasets that are not bound by the constraints of privacy.\n",
    "\n",
    "### 1.1 The Task\n",
    "Make a private version of the Brazil COVID-19 dataset, that could safely be used by anyone to create a COVID-19 survival analysis model, without the risk of (re-)identification of individuals.\n",
    "\n",
    "### 2. Imports\n",
    "Lets get the imports out of the way. We import the required standard and 3rd party libraries and relevant Synthcity modules. We can also set the level of logging here, using Synthcity's bespoke logger. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696e0157",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Standard\n",
    "import sys\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "# 3rd party\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# synthcity\n",
    "import synthcity.logger as log\n",
    "from synthcity.utils import serialization\n",
    "from synthcity.plugins import Plugins\n",
    "from synthcity.plugins.core.dataloader import (GenericDataLoader, SurvivalAnalysisDataLoader)\n",
    "from synthcity.metrics import Metrics\n",
    "\n",
    "# Configure warnings and logging\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Set the level for the logging\n",
    "# log.add(sink=sys.stderr, level=\"DEBUG\")\n",
    "log.remove()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "afc77560",
   "metadata": {},
   "source": [
    "### 3. Load the data\n",
    "\n",
    "Load the data from file into a SurvivalAnalysisDataLoader object. For this we need to pass the names of our `target_column` and our `time_to_event_column` to the data loader. Then we can see the data by calling loader.dataframe() and get the information about the data loader object with loader.info()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51076cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv(f\"../data/Brazil_COVID/covid_normalised_numericalised.csv\")\n",
    "loader = SurvivalAnalysisDataLoader(\n",
    "    X,\n",
    "    target_column=\"is_dead\",\n",
    "    time_to_event_column=\"Days_hospital_to_outcome\",\n",
    "    sensitive_features=[\"Age\", \"Sex\", \"Ethnicity\", \"Region\"],\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "print(loader.info())\n",
    "display(loader.dataframe())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ee1ea129",
   "metadata": {},
   "source": [
    "## 4. Load/Create synthetic datasets\n",
    "\n",
    "We can list the available synthetic generators by calling list() on the Plugins object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be85fd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Plugins().list())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "229d9fbe",
   "metadata": {},
   "source": [
    "From the above list we are going to select the synthetic generation models for privacy: \"dpgan\", \"adsgan\", and \"pategan\". Then we will create and fit the synthetic model before using it to generate a synthetic dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3252ae89",
   "metadata": {},
   "outputs": [],
   "source": [
    "outdir = Path(\"saved_models\")\n",
    "prefix = \"privacy\"\n",
    "n_iter = 100\n",
    "random_state=42\n",
    "models=[\n",
    "    \"dpgan\",\n",
    "    \"adsgan\",\n",
    "    \"pategan\",\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "180e1459",
   "metadata": {},
   "source": [
    "For each model check if there is already a saved version, and if not use get() and fit() to produce one to then save to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4df9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    save_file = outdir / f\"{prefix}.{model}_numericalised_n_iter={n_iter}_rnd={random_state}.bkp\"\n",
    "    \n",
    "    if not Path(save_file).exists():\n",
    "        print(model)\n",
    "        syn_model = Plugins().get(model, random_state=random_state)\n",
    "        syn_model.fit(loader)\n",
    "        serialization.save_to_file(save_file, syn_model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "70a1cb76",
   "metadata": {},
   "source": [
    "## 5. Evaluate the generated synthetic dataset in terms of privacy\n",
    "\n",
    "We can select some metrics to choose. The full list of available metrics can be seen by calling Metrics().list(). We are going to use the metrics associated with detection of the synthetic data and data privacy. Then we will print them to a DataFrame to look at the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b938f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_results = {}\n",
    "for model in models:\n",
    "    print(model)\n",
    "    save_file = outdir / f\"{prefix}.{model}_numericalised_n_iter={n_iter}_rnd={random_state}.bkp\"\n",
    "    syn_model = serialization.load_from_file(save_file)\n",
    "    selected_metrics = {\n",
    "        \"detection\": [\"detection_xgb\", \"detection_mlp\", \"detection_gmm\"],\n",
    "        \"privacy\": [\"delta-presence\", \"k-anonymization\", \"k-map\", \"distinct l-diversity\", \"identifiability_score\"],\n",
    "        'performance': ['linear_model', 'mlp', 'xgb'],\n",
    "    }\n",
    "    my_metrics = Metrics()\n",
    "    selected_metrics_in_my_metrics = {k: my_metrics.list()[k] for k in my_metrics.list().keys() & selected_metrics.keys()}\n",
    "    X_syn = syn_model.generate(count=6882, random_state=random_state)\n",
    "    evaluation = my_metrics.evaluate(\n",
    "        loader,\n",
    "        X_syn,\n",
    "        task_type=\"survival_analysis\",\n",
    "        metrics=selected_metrics_in_my_metrics,\n",
    "        workspace=\"workspace\",\n",
    "    )\n",
    "    # Drop some metrics that we dont need\n",
    "    display_metrics = [\n",
    "      \"performance.xgb.syn_ood.c_index\",\n",
    "      \"performance.linear_model.syn_ood.c_index\",\n",
    "      \"performance.mlp.syn_ood.c_index\",\n",
    "      \"detection.detection_xgb.mean\",\n",
    "      \"detection.detection_mlp.mean\",\n",
    "      \"detection.detection_gmm.mean\",\n",
    "      \"detection.detection_linear.mean\",\n",
    "      \"privacy.k-anonymization.syn\",\n",
    "      \"privacy.k-map.score\",\n",
    "      \"privacy.distinct l-diversity.syn\",\n",
    "      \"privacy.identifiability_score.score\",\n",
    "    ]\n",
    "    evaluation = evaluation.loc[display_metrics]\n",
    "    display(evaluation)\n",
    "    eval_results[model] = evaluation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "79e43b62",
   "metadata": {},
   "source": [
    "### 5.1 Display the evaluation results\n",
    "The above table contains all the information we need to evaluate the methods, but lets convert it to a format where it is easier to compare the methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024dd64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "means = []\n",
    "for plugin in eval_results:\n",
    "    data = eval_results[plugin][\"mean\"]\n",
    "    directions = eval_results[plugin][\"direction\"].to_dict()\n",
    "    means.append(data)\n",
    "\n",
    "out = pd.concat(means, axis=1)\n",
    "out.set_axis(eval_results.keys(), axis=1, inplace=True)\n",
    "\n",
    "bad_highlight = \"background-color: lightcoral;\"\n",
    "ok_highlight = \"background-color: green;\"\n",
    "default = \"\"\n",
    "\n",
    "\n",
    "def highlights(row):\n",
    "    metric = row.name\n",
    "    if directions[metric] == \"minimize\":\n",
    "        best_val = np.min(row.values)\n",
    "        worst_val = np.max(row)\n",
    "    else:\n",
    "        best_val = np.max(row.values)\n",
    "        worst_val = np.min(row)\n",
    "\n",
    "    styles = []\n",
    "    for val in row.values:\n",
    "        if val == best_val:\n",
    "            styles.append(ok_highlight)\n",
    "        elif val == worst_val:\n",
    "            styles.append(bad_highlight)\n",
    "        else:\n",
    "            styles.append(default)\n",
    "\n",
    "    return styles\n",
    "\n",
    "\n",
    "out.style.apply(highlights, axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f645dd61",
   "metadata": {},
   "source": [
    "### 5.2 Results of evaluation\n",
    "\n",
    "We are using three types of metric here:performance, detection and privacy. Performance metrics explain the utility of a synthetic dataset. Detection metrics measure the ability to identify the real data compared to the synthetic data. The privacy metrics measure how easy it would be to re-identify a patient given the quasi-identifying fields in the dataset.\n",
    "Generally, ADSGAN performs best in synthetic data detection and performance tasks, then PATEGAN, and DPGAN tends to perform very poorly.\n",
    "\n",
    "k-anonymization - risk of re-identification is approximately 1/k according to [this paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2528029/). Therefore the risk of re-identification is ~7% for DPGAN 10% for ADSGAN and for PATEGAN it is 11%. In any case there is significant improvement from ground truth k=3.\n",
    "\n",
    "k-map - is a metric where every combination of values for the quasi-identifiers appears at least k times in the synthetic dataset. ADSGAN performs worse than PATEGAN, but DPGAN comes out on top.\n",
    "\n",
    "l-diversity - Is a similar metric to k-anonymization, but ir is also concerned with the diversity of the generalized block. We see the same pattern as for k-anonymization.\n",
    "\n",
    "identifiability_score - Risk of re-identification as defined in [this paper](https://ieeexplore.ieee.org/document/9034117). This is the best for DPGAN. ADSGAN and PATEGAN perform worse.\n",
    "\n",
    "**Conclusion**<br/>\n",
    "Generally, it seems DPGAN performs best in the privacy metrics, but  worst in the other performance and detection. The synthetic data is completely distinguishable from the real data by multiple detection algorithms, meaning it could be said to have very low fidelity. The performance is also poor compared to ADSGAN, meaning it also has low utility. For ADSGAN, on the other hand, detection is not much better than random chance and it score highest in the performance metrics. Therefore the choice of model will depend on your use case. Is fidelity, utility or privacy the most important factor for you? "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5e451888",
   "metadata": {},
   "source": [
    "## 6. Synthetic Data Quality\n",
    "\n",
    "To get a good sense of the quality of the synthetic datasets and validate our previous conclusion. Lets plot the correlation/strength-of-association of features in data-set with both categorical and continuous features using:\n",
    "- Pearson's R for continuous-continuous cases\n",
    "- Correlation Ratio for categorical-continuous cases\n",
    "- Cramer's V or Theil's U for categorical-categorical cases\n",
    "\n",
    "In each of the following plots we are looking for the synthetic data to be as similar to the real data as possible. That is minimal values for Jensen-Shannon distance and pairwise correlation distance, and T-SNEs with similar looking distribution in the representation space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2acd1810",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "for model in models:\n",
    "    print(model)\n",
    "    save_file = outdir / f\"{prefix}.{model}_numericalised_n_iter={n_iter}_rnd={random_state}.bkp\"\n",
    "    if Path(save_file).exists():\n",
    "        syn_model = serialization.load_from_file(save_file)\n",
    "        syn_model.plot(plt, loader, plots=[\"associations\",\"marginal\", \"tsne\"])\n",
    "        plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c90f22f4",
   "metadata": {},
   "source": [
    "## 7. Extension\n",
    "Use the code block below as a space to complete the extension exercises below.\n",
    "\n",
    "### 7.1 Training models on both sets of data\n",
    "1) Use the metrics to get a the performance of a model trained on the real dataset to put our performance scores in context.\n",
    "\n",
    "2) Train your own downstream model on both the original dataset and each of the private datasets we have generated to see if you reach the same conclusion. Which privacy method provides the best performance and what are the trade-offs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4aa622",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "synth-lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "8b1180d7559eadeaa51f0c23b115f584a6e0cc67e9bc1d662a0e6b39392000a4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
