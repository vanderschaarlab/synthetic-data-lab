{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "97e2d93c",
   "metadata": {},
   "source": [
    "# Case Study 2 - Fairness\n",
    "\n",
    "## The Task\n",
    "Train a fair prognostic classifier for COVID-19 patients in Brazil.\n",
    "\n",
    "### Imports\n",
    "Lets get the imports out of the way. We import the required standard and 3rd party libraries and relevant Synthcity modules. We can also set the level of logging here, using Synthcity's bespoke logger. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696e0157",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Standard\n",
    "import sys\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from typing import Any, Tuple\n",
    "from pprint import pprint\n",
    "import itertools\n",
    "\n",
    "# 3rd party\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import auc, accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "\n",
    "# synthcity\n",
    "import synthcity\n",
    "import synthcity.logger as log\n",
    "from synthcity.utils import serialization\n",
    "from synthcity.plugins import Plugins\n",
    "from synthcity.metrics import Metrics\n",
    "from synthcity.plugins.core.dataloader import (GenericDataLoader, SurvivalAnalysisDataLoader)\n",
    "from synthcity.plugins.privacy.plugin_decaf import plugin as decaf_plugin\n",
    "\n",
    "# Configure warnings and logging\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Set the level for the logging\n",
    "log.remove()\n",
    "# log.add(sink=sys.stderr, level=\"INFO\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fb17ab03",
   "metadata": {},
   "source": [
    "## Load the data\n",
    "Next, we can load the data from file and formulate it as a classification problem. To do this we can simply set a time horizon and create an \"is_dead_at_time_horizon\" column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e4f82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_horizon = 14\n",
    "X = pd.read_csv(f\"../data/Brazil_COVID/covid_normalised_numericalised.csv\")\n",
    "\n",
    "X.loc[(X[\"Days_hospital_to_outcome\"] <= time_horizon) & (X[\"is_dead\"] == 1), f\"is_dead_at_time_horizon={time_horizon}\"] = 1\n",
    "X.loc[(X[\"Days_hospital_to_outcome\"] > time_horizon), f\"is_dead_at_time_horizon={time_horizon}\"] = 0\n",
    "X.loc[(X[\"is_dead\"] == 0), f\"is_dead_at_time_horizon={time_horizon}\"] = 0\n",
    "X[f\"is_dead_at_time_horizon={time_horizon}\"] = X[f\"is_dead_at_time_horizon={time_horizon}\"].astype(int)\n",
    "\n",
    "X.drop(columns=[\"is_dead\", \"Days_hospital_to_outcome\"], inplace=True) # drop survival columns as they are not needed for a classification problem\n",
    "display(X)\n",
    "\n",
    "# Define the mappings of the encoded values in the Ethnicity column to the understandable values\n",
    "ethnicity_mapper = {\n",
    "    0: \"Mixed\",\n",
    "    1: \"White\",\n",
    "    2: \"Black\",\n",
    "    3: \"East Asian\",\n",
    "    4: \"Indigenous\",\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "17e14620",
   "metadata": {},
   "source": [
    "### Potential issue\n",
    "\n",
    "The Brazilian population is made up of people of different ethnicities in different proportions. We should check the frequency for each ethnicity to see how evenly distributed our data is across ethnicity. Lets create a plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c74515e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ethnicity_frequency_data = pd.DataFrame(data=X[\"Ethnicity\"].value_counts().rename(ethnicity_mapper), columns=[\"Ethnicity\"]).reset_index().rename(columns={\"index\": \"Ethnicity\", \"Ethnicity\": \"Ethnicity count\"})\n",
    "print(sns.barplot(data=ethnicity_frequency_data, x=\"Ethnicity\", y=\"Ethnicity count\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d4424ae0",
   "metadata": {},
   "source": [
    "The population in our dataset is overwhelmingly white an mixed, with little representation of black, East Asian and indigenous people. This poses a problem for us.\n",
    "\n",
    "# The Problem\n",
    "We need to train a prognostic classifier for the whole population. Having little representation from some parts of the population means that any classifier we train on this data is going to be susceptible to bias. Lets train an XGBoost classifier on the whole dataset then test it on each ethnicity. This will show us the extent of the problem, as we will be able to see any disparity between model performance across the different groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1645e4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = X[\"is_dead_at_time_horizon=14\"]\n",
    "X_in = X.drop(columns=[\"is_dead_at_time_horizon=14\"])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_in, y, random_state=4)\n",
    "X_train.reset_index(drop=True, inplace=True)\n",
    "X_test.reset_index(drop=True, inplace=True)\n",
    "y_train.reset_index(drop=True, inplace=True)\n",
    "y_test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Train model on whole dataset\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    n_estimators=2000,\n",
    "    learning_rate=0.01,\n",
    "    max_depth=5,\n",
    "    subsample=0.8, \n",
    "    colsample_bytree=1, \n",
    "    gamma=1, \n",
    "    objective=\"binary:logistic\",\n",
    "    random_state=42,\n",
    ")\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "ethnicity_idxes = X_in[\"Ethnicity\"].unique()\n",
    "ethnicity_idxes.sort()\n",
    "ethnicities = [ethnicity_mapper[e] for e in ethnicity_idxes]\n",
    "\n",
    "calculated_accuracy_score = accuracy_score(y_train, xgb_model.predict(X_train))\n",
    "print(f\"Evaluating accuracy on train set: {calculated_accuracy_score}\")\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "calculated_accuracy_score = accuracy_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "f, axes = plt.subplots(2, 3, figsize=(20, 10))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=xgb_model.classes_)\n",
    "disp.plot(ax=axes[0,0])\n",
    "disp.ax_.set_title(f\"Whole test dataset: {calculated_accuracy_score}\")\n",
    "\n",
    "for ethnicity_idx in ethnicity_idxes:\n",
    "    X_test_per_ethnicity = X_test.loc[X_test[\"Ethnicity\"] == ethnicity_idx]\n",
    "    test_records_per_ethnicity_indicies = X_test_per_ethnicity.index\n",
    "\n",
    "    y_pred = xgb_model.predict(X_test_per_ethnicity)\n",
    "    y_true = y_test.iloc[test_records_per_ethnicity_indicies]\n",
    "\n",
    "    calculated_accuracy_score = accuracy_score(y_true, y_pred)\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=xgb_model.classes_)\n",
    "    ax_index = [0, ethnicity_idx + 1] if ethnicity_idx <= 1 else [1, (ethnicity_idx + 1) % 3]\n",
    "    disp.plot(ax=axes[ax_index[0], ax_index[1]])\n",
    "    disp.ax_.set_title(f\"Ethnicity: {ethnicity_mapper[ethnicity_idx]} | Performance: {calculated_accuracy_score}\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ff1d2e82",
   "metadata": {},
   "source": [
    "As you can see the performance of the model on the subpopulation whose ethnicity is Black is significantly worse than the overall performance. Interestingly, however the model performs better on the East Asian subpopulation. This is likely to be due to random chance, i.e. it happens that the East Asian patients in this sample had features that are good predictors of the outcome, but this would not necessarily be true for a bigger sample from the same population. The Indigenous population is so poorly represented in the dataset, with only 3 records, that it is difficult to even accurately assess performance. However, the indication we have from these three records suggests performance may be poor.\n",
    "\n",
    "This confirms by using a naive method like the one above, we would create a model that systematically performs worse for people of one ethnicity compared to another. This unfairness must be addressed.\n",
    "\n",
    "# The solution - Augment the dataset to improve the fairness\n",
    "\n",
    "First we load the data with the GenericDataLoader. For this we need to pass the names of our `target_column` to the data loader. Then we can see the data by calling loader.dataframe() and we could also get the infomation about the data loader object with loader.info().\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096390b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = GenericDataLoader(\n",
    "    X,\n",
    "    target_column=f\"is_dead_at_time_horizon={time_horizon}\",\n",
    "    sensitive_features=[\"Age\", \"Sex\", \"Ethnicity\", \"Region\"],\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "display(loader.dataframe())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "aaa9487e",
   "metadata": {},
   "source": [
    "## Generate the synthetic data\n",
    "Now we can select our choice of synthetic model, using the Plugins.get() syntax. Then we need to fit it to our data before we generate the new records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8edf5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"fairness.conditional_augmentation\"\n",
    "model = \"ctgan\"\n",
    "\n",
    "count = 6882 # set the count equal to the number of rows in the original dataset\n",
    "cond = [(i % 5) for i in range(count)] # set cond to an equal proportion of each index to encourage an equal a split as possible\n",
    "print(model)\n",
    "\n",
    "save_file = Path(\"saved_models\") / f\"{prefix}_{model}_numericalised_2.bkp\"\n",
    "if Path(save_file).exists():\n",
    "    syn_model = serialization.load_from_file(save_file)\n",
    "else:\n",
    "    syn_model = Plugins().get(model)\n",
    "    syn_model.fit(loader, cond=loader[\"Ethnicity\"])\n",
    "    serialization.save_to_file(save_file, syn_model)\n",
    "\n",
    "syn_data = syn_model.generate(count=count, cond=cond).dataframe()\n",
    "display(syn_data)\n",
    "print(\"Here is the ethnicity breakdown for the new synthetic dataset:\")\n",
    "print(syn_data[\"Ethnicity\"].value_counts().rename(ethnicity_mapper))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "532fd0ca",
   "metadata": {},
   "source": [
    "Check the ethnicity breakdown again now to check we have augmented the under-represented groups properly. This is important as the conditional only optimizes the GAN here it does not guarantee that generated samples perfectly meet that condition. If you require rules to be strictly adhered to, use `Constraints` instead. \n",
    "\n",
    "# Lets try our classifier again with the synthetic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac9707a",
   "metadata": {},
   "outputs": [],
   "source": [
    "syn_y = syn_data[\"is_dead_at_time_horizon=14\"]\n",
    "syn_X_in = syn_data.drop(columns=[\"is_dead_at_time_horizon=14\"])\n",
    "\n",
    "syn_X_train, syn_X_test, syn_y_train, syn_y_test = train_test_split(syn_X_in, syn_y, random_state=4)\n",
    "syn_X_train.reset_index(drop=True, inplace=True)\n",
    "syn_X_test.reset_index(drop=True, inplace=True)\n",
    "syn_y_train.reset_index(drop=True, inplace=True)\n",
    "syn_y_test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Train model on whole dataset\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    n_estimators=2000,\n",
    "    learning_rate=0.01,\n",
    "    max_depth=5,\n",
    "    subsample=0.8, \n",
    "    colsample_bytree=1, \n",
    "    gamma=1, \n",
    "    objective=\"binary:logistic\",\n",
    "    random_state=42,\n",
    ")\n",
    "xgb_model.fit(syn_X_train, syn_y_train)\n",
    "\n",
    "ethnicity_idxes = syn_X_in[\"Ethnicity\"].unique()\n",
    "ethnicity_idxes.sort()\n",
    "ethnicities = [ethnicity_mapper[e] for e in ethnicity_idxes]\n",
    "\n",
    "calculated_accuracy_score = accuracy_score(syn_y_train, xgb_model.predict(syn_X_train))\n",
    "print(f\"evaluating train set: {calculated_accuracy_score}\")\n",
    "syn_y_pred = xgb_model.predict(syn_X_test)\n",
    "calculated_accuracy_score = accuracy_score(syn_y_test, syn_y_pred)\n",
    "\n",
    "\n",
    "f, axes = plt.subplots(2, 3, figsize=(20, 10))\n",
    "\n",
    "cm = confusion_matrix(syn_y_test, syn_y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=xgb_model.classes_)\n",
    "disp.plot(ax=axes[0,0])\n",
    "disp.ax_.set_title(f\"Whole Test Dataset | Performance: {calculated_accuracy_score}\")\n",
    "\n",
    "for ethnicity_idx in ethnicity_idxes:\n",
    "    syn_X_test_per_ethnicity = syn_X_test.loc[syn_X_test[\"Ethnicity\"] == ethnicity_idx]\n",
    "    test_records_per_ethnicity_indicies = syn_X_test_per_ethnicity.index\n",
    "\n",
    "    syn_y_pred = xgb_model.predict(syn_X_test_per_ethnicity)\n",
    "    syn_y_true = syn_y_test.iloc[test_records_per_ethnicity_indicies]\n",
    "\n",
    "    calculated_accuracy_score = accuracy_score(syn_y_true, syn_y_pred)\n",
    "\n",
    "    cm = confusion_matrix(syn_y_true, syn_y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=xgb_model.classes_)\n",
    "    ax_index = [0, ethnicity_idx + 1] if ethnicity_idx <= 1 else [1, (ethnicity_idx + 1) % 3]\n",
    "    disp.plot(ax=axes[ax_index[0], ax_index[1]])\n",
    "    disp.ax_.set_title(f\"Ethnicity: {ethnicity_mapper[ethnicity_idx]} | Performance: {calculated_accuracy_score}\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ee1ea129",
   "metadata": {},
   "source": [
    "As you can hopefully see the new model trained on the synthetic data performs more similarly across the different populations. \n",
    "\n",
    "Why not play with the different synthetic data generation methods and their parameters to see if you can achieve the same improvement in fairness, but with a higher performance? If you need help identifying the right methods then, remember you can list the available plugins with `Plugins().list()` and to learn what they do refer to the [docs](https://synthcity.readthedocs.io/en/latest/generators.html).\n",
    "\n",
    "# Removing bias via causal generation with DECAF\n",
    "### Load the data\n",
    "Lets load the data from file again to make sure we are working with the correct data and nothing has changed. As before we willconstruct it as a classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e3bdf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_horizon = 14\n",
    "X = pd.read_csv(f\"../data/Brazil_COVID/covid_normalised_numericalised.csv\")\n",
    "\n",
    "X.loc[(X[\"Days_hospital_to_outcome\"] <= time_horizon) & (X[\"is_dead\"] == 1), f\"is_dead_at_time_horizon={time_horizon}\"] = 1\n",
    "X.loc[(X[\"Days_hospital_to_outcome\"] > time_horizon), f\"is_dead_at_time_horizon={time_horizon}\"] = 0\n",
    "X.loc[(X[\"is_dead\"] == 0), f\"is_dead_at_time_horizon={time_horizon}\"] = 0\n",
    "X[f\"is_dead_at_time_horizon={time_horizon}\"] = X[f\"is_dead_at_time_horizon={time_horizon}\"].astype(int)\n",
    "\n",
    "X.drop(columns=[\"is_dead\", \"Days_hospital_to_outcome\"], inplace=True) # drop survival columns as they are not needed for a classification problem\n",
    "\n",
    "loader = GenericDataLoader(\n",
    "    X,\n",
    "    target_column=\"is_dead_at_time_horizon=14\",\n",
    "    sensitive_features=[\"Ethnicity\"],\n",
    "    # sensitive_features=[\"Age\", \"Sex\", \"Ethnicity\", \"Region\"], # How to handle multiple sensitive columns?\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "display(loader.dataframe())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "153914b3",
   "metadata": {},
   "source": [
    "### Create and fit syn_model using DECAF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb660f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"fairness.causal_generation\"\n",
    "model = \"decaf\"\n",
    "n_iter = 20\n",
    "count = 6882 # set the count equal to the number of rows in the original dataset\n",
    "print(model)\n",
    "\n",
    "save_file = Path(\"saved_models\") / f\"{prefix}_{model}_n_iter={n_iter}_numericalised.bkp\"\n",
    "if Path(save_file).exists():\n",
    "    syn_model = serialization.load_from_file(save_file)\n",
    "else:\n",
    "    syn_model = decaf_plugin(struct_learning_enabled=True, n_iter=n_iter) # Pass struct_learning_enabled=True in order for the syn_model to learn the Dag\n",
    "    dag_before = syn_model.get_dag(loader.dataframe())\n",
    "    syn_model.fit(loader, dag=dag_before)\n",
    "    print(syn_model.get_dag(loader.dataframe()))\n",
    "    serialization.save_to_file(save_file, syn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8f17f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "bias={\"Ethnicity\": [\"is_dead_at_time_horizon=14\"]} # This will probably need to be column indices\n",
    "decaf_syn_data = syn_model.generate(count, biased_edges=bias)\n",
    "print(syn_model.get_dag(decaf_syn_data.dataframe()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5eb50c86",
   "metadata": {},
   "source": [
    "## DECAF fairness tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90851f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FTU_score(loader):\n",
    "\n",
    "    # Input: data to be evaluated (synthetic or real)\n",
    "\n",
    "    # Split the data into D_tr and D_eval for training and validation\n",
    "    X, y = loader[loader.static_features].copy(), loader[loader.target_column].copy()\n",
    "    X.drop(columns=[\"is_dead_at_time_horizon=14\"], inplace=True)\n",
    "    X_train, X_eval, y_train, y_eval = train_test_split(X, y, train_size=0.6, random_state=4)\n",
    "    X_train.reset_index(drop=True, inplace=True)\n",
    "    X_eval.reset_index(drop=True, inplace=True)\n",
    "    y_train.reset_index(drop=True, inplace=True)\n",
    "    y_eval.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Train a classifier on D_tr to learn prediction rule (X, A) -> Y\n",
    "    xgb_model = xgb.XGBClassifier(\n",
    "        n_estimators=500,\n",
    "        learning_rate=0.01,\n",
    "        max_depth=3,\n",
    "        subsample=0.8, \n",
    "        colsample_bytree=1, \n",
    "        gamma=1, \n",
    "        objective=\"binary:logistic\",\n",
    "        random_state=42,\n",
    "    )\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "    # for each pair of feature values\n",
    "    ftu_list = []\n",
    "    sensitive_feature_values = loader[loader.sensitive_features[0]].unique()\n",
    "    for val1, val2 in itertools.combinations(sensitive_feature_values,2):\n",
    "        # Create a new dataset D_eval(1) by setting A := 1 for all records in D_eval, the X is kept the same.\n",
    "        # Create D_eval(0) similarly.\n",
    "        X_eval_1 = X_eval.copy()\n",
    "        X_eval_2 = X_eval.copy()\n",
    "\n",
    "        X_eval_1[loader.sensitive_features[0]] = val1\n",
    "        X_eval_2[loader.sensitive_features[0]] = val2\n",
    "    \n",
    "        # Pass D_eval(1) to the classifier to get predictions \\hat{Y}(1). \n",
    "        # Similarly, make predictions on D_eval(0) to get \\hat{Y}(0).\n",
    "        y_hat_1 = xgb_model.predict(X_eval_1)\n",
    "        y_hat_2 = xgb_model.predict(X_eval_2)\n",
    "\n",
    "        # Calculate the proportion of \\hat{Y}(1) = 1, denoted as P1.\n",
    "        # Calculate the proportion of \\hat{Y}(0) = 1, denoted as P0.\n",
    "        p1 = y_hat_1.sum() / len(y_hat_1)\n",
    "        p2 = y_hat_2.sum() / len(y_hat_2)\n",
    "\n",
    "        # FTU = abs(P0 - P1)\n",
    "        ftu = abs(p1 - p2)\n",
    "        ftu_list.append(ftu)\n",
    "    return np.median(ftu_list)\n",
    "\n",
    "def demographic_parity_score(loader):\n",
    "\n",
    "    # Input: data to be evaluated (synthetic or real)\n",
    "\n",
    "    # Split the data into D_tr and D_eval for training and validation\n",
    "    X, y = loader[loader.static_features].copy(), loader[loader.target_column].copy()\n",
    "    X.drop(columns=[\"is_dead_at_time_horizon=14\"], inplace=True)\n",
    "    X_train, X_eval, y_train, y_eval = train_test_split(X, y, train_size=0.6, random_state=4)\n",
    "    X_train.reset_index(drop=True, inplace=True)\n",
    "    X_eval.reset_index(drop=True, inplace=True)\n",
    "    y_train.reset_index(drop=True, inplace=True)\n",
    "    y_eval.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Train a classifier on D_tr to learn prediction rule (X, A) -> Y\n",
    "    xgb_model = xgb.XGBClassifier(\n",
    "        n_estimators=200,\n",
    "        learning_rate=0.01,\n",
    "        max_depth=3,\n",
    "        subsample=0.8, \n",
    "        colsample_bytree=1, \n",
    "        gamma=1, \n",
    "        objective=\"binary:logistic\",\n",
    "        random_state=42,\n",
    "    )\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "    # for each pair of feature values\n",
    "    demographic_parity_list = []\n",
    "    sensitive_feature_values = loader[loader.sensitive_features[0]].unique()\n",
    "    for val1, val2 in itertools.combinations(sensitive_feature_values,2):\n",
    "\n",
    "        # Create a new dataset D_eval(1) by only keeping the records in D_eval that have A = 1. Remove the records with A = 0.\n",
    "        # Create D_eval(0) similarly.\n",
    "        X_eval_0 = X_eval.loc[X_eval[loader.sensitive_features[0]] == val1].copy()\n",
    "        X_eval_1 = X_eval.loc[X_eval[loader.sensitive_features[0]] == val2].copy()\n",
    "        # display(X_eval_0)\n",
    "        # display(X_eval_1)\n",
    "\n",
    "        # Pass D_eval(1) to the classifier to get predictions \\hat{Y}(1). \n",
    "        # Similarly, make predictions on D_eval(0) to get \\hat{Y}(0).\n",
    "        y_hat_0 = xgb_model.predict(X_eval_0)\n",
    "        y_hat_1 = xgb_model.predict(X_eval_1)\n",
    "\n",
    "        # Calculate the proportion of \\hat{Y}(1) = 1, denoted as P1.\n",
    "        # Calculate the proportion of \\hat{Y}(0) = 1, denoted as P0.\n",
    "        p0 = y_hat_0.sum() / len(y_hat_0)\n",
    "        p1 = y_hat_1.sum() / len(y_hat_1)\n",
    "\n",
    "        # DP = abs(P0 - P1)\n",
    "        DP = abs(p0 - p1)\n",
    "        demographic_parity_list.append(DP)\n",
    "    return np.mean(demographic_parity_list)\n",
    "\n",
    "FTU_score_gt = FTU_score(loader)\n",
    "FTU_score_syn = FTU_score(decaf_syn_data)\n",
    "\n",
    "print(f\"Fairness through unawareness scores \\nreal data: {FTU_score_gt} | synthetic data: {FTU_score_syn}\")\n",
    "\n",
    "demographic_parity_score_gt = demographic_parity_score(loader)\n",
    "demographic_parity_score_syn = demographic_parity_score(decaf_syn_data)\n",
    "\n",
    "print(f\"Demographic Parity scores \\nreal data: {demographic_parity_score_gt} | synthetic data: {demographic_parity_score_syn}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "71429207",
   "metadata": {},
   "source": [
    "# Some visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7244f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "synth-lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "8b1180d7559eadeaa51f0c23b115f584a6e0cc67e9bc1d662a0e6b39392000a4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
