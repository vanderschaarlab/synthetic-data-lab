{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "97e2d93c",
   "metadata": {},
   "source": [
    "# Case Study 2 - Fairness\n",
    "These notebooks are also available on Google Colab. This enables you to run the notebooks without having to set up an environment locally and gives you access to GPUs to run the notebooks on.\n",
    "\n",
    "[![Run in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1JOstMJmhI2wcufyBqZ1iV3YqOdThJ-_U?usp=sharing#scrollTo=mCX2hPceiAet)\n",
    "\n",
    "## 1. Introduction\n",
    "One common problem with some machine learning models is an unfair bias in the training data leading to a models that systematically perform worse for some populations. In this case study we will address the issue of fairness by reducing the bias in a generated synthetic dataset.\n",
    "\n",
    "### 1.1 The Task\n",
    "Train a fair prognostic classifier for COVID-19 patients in Brazil.\n",
    "\n",
    "## 2. Imports\n",
    "Lets get the imports out of the way. We import the required standard and 3rd party libraries and relevant Synthcity modules. We can also set the level of logging here, using Synthcity's bespoke logger. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696e0157",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Standard\n",
    "import sys\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from typing import Any, Tuple\n",
    "import itertools\n",
    "\n",
    "# 3rd party\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import networkx as nx\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from graphviz import Digraph\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# synthcity\n",
    "import synthcity\n",
    "import synthcity.logger as log\n",
    "from synthcity.utils import serialization\n",
    "from synthcity.plugins import Plugins\n",
    "from synthcity.metrics import Metrics\n",
    "from synthcity.plugins.core.dataloader import (GenericDataLoader, SurvivalAnalysisDataLoader)\n",
    "from synthcity.plugins.privacy.plugin_decaf import plugin as decaf_plugin\n",
    "from synthcity.plugins.core.constraints import Constraints\n",
    "\n",
    "# Synthetic-data-lab\n",
    "from utils import fairness_scores\n",
    "from utils import plot_dag\n",
    "\n",
    "# Configure warnings and logging\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Set the level for the logging\n",
    "log.remove()\n",
    "# log.add(sink=sys.stderr, level=\"INFO\")\n",
    "\n",
    "\n",
    "# Set up paths to resources\n",
    "FAIR_RES_PATH = Path(\"../resources/fairness/\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fb17ab03",
   "metadata": {},
   "source": [
    "## 3. Load the data\n",
    "Next, we can load the data from file and formulate it as a classification problem. To do this we can simply set a time horizon and create an \"is_dead_at_time_horizon\" column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e4f82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_horizon = 14\n",
    "X = pd.read_csv(f\"../data/Brazil_COVID/covid_normalised_numericalised.csv\")\n",
    "\n",
    "X.loc[(X[\"Days_hospital_to_outcome\"] <= time_horizon) & (X[\"is_dead\"] == 1), f\"is_dead_at_time_horizon={time_horizon}\"] = 1\n",
    "X.loc[(X[\"Days_hospital_to_outcome\"] > time_horizon), f\"is_dead_at_time_horizon={time_horizon}\"] = 0\n",
    "X.loc[(X[\"is_dead\"] == 0), f\"is_dead_at_time_horizon={time_horizon}\"] = 0\n",
    "X[f\"is_dead_at_time_horizon={time_horizon}\"] = X[f\"is_dead_at_time_horizon={time_horizon}\"].astype(int)\n",
    "\n",
    "X.drop(columns=[\"is_dead\", \"Days_hospital_to_outcome\"], inplace=True) # drop survival columns as they are not needed for a classification problem\n",
    "display(X)\n",
    "\n",
    "# Define the mappings of the encoded values in the Ethnicity column to the understandable values\n",
    "ethnicity_mapper = {\n",
    "    0: \"Mixed\",\n",
    "    1: \"White\",\n",
    "    2: \"Black\",\n",
    "    3: \"East Asian\",\n",
    "    4: \"Indigenous\",\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "17e14620",
   "metadata": {},
   "source": [
    "## 4. Potential issue\n",
    "\n",
    "The Brazilian population is made up of people of different ethnicities in different proportions. We should check the frequency for each ethnicity to see how evenly distributed our data is across ethnicity. Lets create a plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c74515e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ethnicity_frequency_data = pd.DataFrame(data=X[\"Ethnicity\"].value_counts().rename(ethnicity_mapper), columns=[\"Ethnicity\"]).reset_index().rename(columns={\"index\": \"Ethnicity\", \"Ethnicity\": \"Ethnicity count\"})\n",
    "sns.barplot(data=ethnicity_frequency_data, x=\"Ethnicity\", y=\"Ethnicity count\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d4424ae0",
   "metadata": {},
   "source": [
    "The population in our dataset is overwhelmingly white and mixed, with little representation of black, East Asian and indigenous people. This poses a problem for us.\n",
    "\n",
    "## 5. The Problem\n",
    "We need a prognostic classifier for the whole population. Having little representation from some parts of the population means that any classifier we train on this data is going to be susceptible to bias. Lets test an `RandomForestClassifier` classifier on the whole dataset then test it on each ethnicity. This will show us the extent of the problem, as we will be able to see any disparity between model performance across the different groups.\n",
    "\n",
    "### 5.1 set up the data\n",
    "Set up the data splits, using train_test_split from sklearn, for a prognostic classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1645e4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = X[\"is_dead_at_time_horizon=14\"]\n",
    "X_in = X.drop(columns=[\"is_dead_at_time_horizon=14\"])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_in, y, random_state=4)\n",
    "X_train.reset_index(drop=True, inplace=True)\n",
    "X_test.reset_index(drop=True, inplace=True)\n",
    "y_train.reset_index(drop=True, inplace=True)\n",
    "y_test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "265a9a43",
   "metadata": {},
   "source": [
    "### 5.2 Load the classifier\n",
    "Load the trained `RandomForestClassifier`, which has been trained on the whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f58702",
   "metadata": {},
   "outputs": [],
   "source": [
    "prognostic_model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    criterion='gini',\n",
    "    max_depth=None,\n",
    "    random_state=42,\n",
    "    verbose=0,\n",
    "    warm_start=False,\n",
    ")\n",
    "\n",
    "saved_model_path = FAIR_RES_PATH / \"fairness_cond_aug_random_forest_real_data.sav\"\n",
    "\n",
    "# # The saved model was trained with the following code\n",
    "# prognostic_model.fit(X_train, y_train)\n",
    "# with open(saved_model_path, 'wb') as f:\n",
    "#     pickle.dump(prognostic_model, f)\n",
    "\n",
    "# Load the model trained on the whole dataset\n",
    "with open(saved_model_path, \"rb\") as f:\n",
    "    prognostic_model = pickle.load(f)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4829e0f2",
   "metadata": {},
   "source": [
    "### 2.6.3 Evaluate the classifier\n",
    "Evaluate the overall accuracy of the classifier on the whole dataset. We can see the accuracy on both the train and test sets. This notebook is set up for you to select a preferred performance score of either sklearn's `accuracy_score` or `f1_score`. Feel free to set `performance_score` to either in the line below, or a metric of you choice!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1865db",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_score = accuracy_score\n",
    "calculated_performance_score = performance_score(y_train, prognostic_model.predict(X_train))\n",
    "print(f\"Evaluating accuracy on train set: {calculated_performance_score:0.4f}\")\n",
    "\n",
    "# Predicted values for whole dataset\n",
    "y_pred = prognostic_model.predict(X_test)\n",
    "\n",
    "calculated_performance_score = performance_score(y_test, y_pred)\n",
    "print(f\"Evaluating accuracy on test set: {calculated_performance_score:0.4f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1511a2e0",
   "metadata": {},
   "source": [
    "### 5.4 Confusion Matrices\n",
    "Create the confusion matrix for each of the ethnicities and the whole dataset to compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73482d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the figure axis\n",
    "f, axes = plt.subplots(2, 3, figsize=(20, 10))\n",
    "\n",
    "# Create the whole dataset confusion matrix and add it to the figure\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=prognostic_model.classes_)\n",
    "disp.plot(ax=axes[0,0])\n",
    "disp.ax_.set_title(f\"Whole test dataset: {calculated_performance_score}\")\n",
    "\n",
    "# Get the indices to loop through\n",
    "ethnicity_idxes = X_in[\"Ethnicity\"].unique()\n",
    "ethnicity_idxes.sort()\n",
    "\n",
    "# for each ethnicity create a confusion matrix\n",
    "for ethnicity_idx in ethnicity_idxes:\n",
    "    # Get the slice of the dataset for each ethnicity\n",
    "    X_test_per_ethnicity = X_test.loc[X_test[\"Ethnicity\"] == ethnicity_idx]\n",
    "    test_records_per_ethnicity_indices = X_test_per_ethnicity.index\n",
    "    y_true = y_test.iloc[test_records_per_ethnicity_indices]\n",
    "\n",
    "    # Generate prediction values for each ethnicity subpopulation\n",
    "    y_pred_per_ethnicity = prognostic_model.predict(X_test_per_ethnicity)\n",
    "\n",
    "    # Calculate the model performance for each ethnicity subpopulation\n",
    "    calculated_performance_score = performance_score(y_true, y_pred_per_ethnicity)\n",
    "\n",
    "    # Generate the confusion matrix and add it to the figure\n",
    "    cm = confusion_matrix(y_true, y_pred_per_ethnicity)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=prognostic_model.classes_)\n",
    "    ax_index = [0, ethnicity_idx + 1] if ethnicity_idx <= 1 else [1, (ethnicity_idx + 1) % 3]\n",
    "    disp.plot(ax=axes[ax_index[0], ax_index[1]])\n",
    "    disp.ax_.set_title(f\"Ethnicity: {ethnicity_mapper[ethnicity_idx]} | Performance: {calculated_performance_score:0.4f}\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ff1d2e82",
   "metadata": {},
   "source": [
    "As you can see the performance of the model on the black population is significantly worse than the overall performance. Interestingly, however the model performs better on the East Asian subpopulation. This is likely to be due to random chance, i.e. it happens that the East Asian patients in this sample had features that are good predictors of the outcome, but this would not necessarily be true for a bigger sample from the same population. The Indigenous population is so poorly represented in the dataset, with only 3 records, that it is difficult to even accurately assess performance. However, the indication we have from these three records suggests performance may be poor.\n",
    "\n",
    "This confirms by using a naive method like the one above, we would create a model that systematically performs worse for people of one ethnicity compared to another. This unfairness must be addressed.\n",
    "\n",
    "## 6. The solution - Augment the dataset to improve the fairness\n",
    "\n",
    "### 6.1 Load the data with the synthcity module\n",
    "First we load the data with the GenericDataLoader. For this we need to pass the names of our `target_column` to the data loader. Then we can see the data by calling loader.dataframe() and we could also get the information about the data loader object with loader.info().\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096390b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = GenericDataLoader(\n",
    "    X,\n",
    "    target_column=f\"is_dead_at_time_horizon={time_horizon}\",\n",
    "    sensitive_features=[\"Ethnicity\"],\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "display(loader.dataframe())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "aaa9487e",
   "metadata": {},
   "source": [
    "### 6.2 Load/Create the synthetic data model\n",
    "We are now going to generate synthetic data with a condition such that the new dataset is more balanced with regard to ethnicity. We will first define some values which we will use below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8edf5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"ctgan\"\n",
    "prefix = \"fairness.conditional_augmentation\"\n",
    "random_state = 42"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7a039a6d",
   "metadata": {},
   "source": [
    "We will now either create and fit a synthetic data model then save that model to file, or load one we have already saved from file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3f6a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define saved model name\n",
    "save_file = Path(\"saved_models\") / f\"{prefix}_{model}_numericalised_rnd={random_state}.bkp\"\n",
    "print(save_file)\n",
    "# Load if available\n",
    "if Path(save_file).exists():\n",
    "    syn_model = serialization.load_from_file(save_file)\n",
    "# create and fit if not available\n",
    "else:\n",
    "    syn_model = Plugins().get(model, random_state=random_state)\n",
    "    syn_model.fit(loader, cond=loader[\"Ethnicity\"])\n",
    "    serialization.save_to_file(save_file, syn_model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "292ff30e",
   "metadata": {},
   "source": [
    "### 6.3 Generate fairer data\n",
    "Use the synthetic data model to generate data using the `cond` argument to try and make the data evenly distributed across ethnicity. We will then augment the original, real dataset with the synthetic records from the under-represented ethnicities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd53bdd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 6882 # set the count equal to the number of rows in the original dataset for a fair comparison\n",
    "cond = [(i % 5) for i in range(count)] # set cond to an equal proportion of each  minority index\n",
    "syn_data = syn_model.generate(count=count, cond=cond, random_state=random_state).dataframe()\n",
    "augmented_data = pd.concat([\n",
    "    X,\n",
    "    syn_data.loc[syn_data[\"Ethnicity\"] >= 2],\n",
    "])\n",
    "\n",
    "display(augmented_data)\n",
    "\n",
    "print(\"Here is the ethnicity breakdown for the real dataset:\")\n",
    "print(loader[\"Ethnicity\"].value_counts().rename(ethnicity_mapper))\n",
    "print(\"\\nHere is the ethnicity breakdown for the synthetic dataset:\")\n",
    "print(syn_data[\"Ethnicity\"].value_counts().rename(ethnicity_mapper))\n",
    "print(\"\\nHere is the ethnicity breakdown for the augmented dataset:\")\n",
    "print(augmented_data[\"Ethnicity\"].value_counts().rename(ethnicity_mapper))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "532fd0ca",
   "metadata": {},
   "source": [
    "Check the ethnicity breakdown again now to check we have augmented the under-represented groups properly. This is important as the conditional only optimizes the GAN here it does not guarantee that generated samples perfectly meet that condition. If you require rules to be strictly adhered to, use `Constraints` instead. \n",
    "\n",
    "### 6.4 Re-evaluate the classifier on the new, fairer dataset\n",
    "Lets try our classifier again with the synthetic dataset. First we need to set up the synthetic data as we did before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac9707a",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_y = augmented_data[\"is_dead_at_time_horizon=14\"]\n",
    "augmented_X = augmented_data.drop(columns=[\"is_dead_at_time_horizon=14\"])\n",
    "augmented_y.reset_index(drop=True, inplace=True)\n",
    "augmented_X.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4c9ce635",
   "metadata": {},
   "source": [
    "\n",
    "We need a model trained on the new data. We can load this from file, as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa5cdd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model_path = FAIR_RES_PATH / \"fairness_cond_aug_random_forest_augmented_data.sav\"\n",
    "\n",
    "# # The saved model was trained with the following code\n",
    "# prognostic_model.fit(augmented_X, augmented_y)\n",
    "# with open(saved_model_path, 'wb') as f:\n",
    "#     pickle.dump(prognostic_model, f)\n",
    "\n",
    "    \n",
    "# Load the model trained on the whole dataset\n",
    "with open(saved_model_path, \"rb\") as f:\n",
    "    prognostic_model = pickle.load(f)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "228b85b5",
   "metadata": {},
   "source": [
    "Evaluate the performance of the model on the real dataset according to the \"train-on-synthetic, test-on-real rule\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8d8191",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = prognostic_model.predict(X_test)\n",
    "calculated_performance_score = performance_score(y_test, y_pred)\n",
    "print(f\"evaluating test set: {calculated_performance_score:0.4f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c83874ab",
   "metadata": {},
   "source": [
    "## 6.5 New confusion matrices\n",
    "Create the confusion matrix for the synthetic dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532da12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the figure axis\n",
    "f, axes = plt.subplots(2, 3, figsize=(20, 10))\n",
    "\n",
    "# Create the whole dataset confusion matrix and add it to the figure\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=prognostic_model.classes_)\n",
    "disp.plot(ax=axes[0,0])\n",
    "# disp.plot(ax=axes[0])\n",
    "disp.ax_.set_title(f\"Whole Test Dataset | Performance: {calculated_performance_score:0.4f}\")\n",
    "\n",
    "# Get the indices to loop through\n",
    "ethnicity_idxes = augmented_X[\"Ethnicity\"].unique()\n",
    "ethnicity_idxes.sort()\n",
    "\n",
    "# for each ethnicity create a confusion matrix\n",
    "for ethnicity_idx in ethnicity_idxes:\n",
    "    # Get the slice of the dataset for each ethnicity\n",
    "    X_test_per_ethnicity = X_test.loc[X_test[\"Ethnicity\"] == ethnicity_idx]\n",
    "    test_records_per_ethnicity_indicies = X_test_per_ethnicity.index\n",
    "    y_true_per_ethnicity = y_test.iloc[test_records_per_ethnicity_indicies]\n",
    "\n",
    "    # Generate prediction values for each ethnicity subpopulation\n",
    "    y_pred_per_ethnicity = prognostic_model.predict(X_test_per_ethnicity)\n",
    "\n",
    "    # Calculate the model performance for each ethnicity subpopulation\n",
    "    calculated_performance_score = performance_score(y_true_per_ethnicity, y_pred_per_ethnicity)\n",
    "\n",
    "    # Generate the confusion matrix and add it to the figure\n",
    "    cm = confusion_matrix(y_true_per_ethnicity, y_pred_per_ethnicity)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=prognostic_model.classes_)\n",
    "    # disp.plot(ax=axes[ethnicity_idx + 1])\n",
    "    ax_index = [0, ethnicity_idx + 1] if ethnicity_idx <= 1 else [1, (ethnicity_idx + 1) % 3]\n",
    "    disp.plot(ax=axes[ax_index[0], ax_index[1]])\n",
    "    disp.ax_.set_title(f\"Ethnicity: {ethnicity_mapper[ethnicity_idx]} | Performance: {calculated_performance_score:0.4f}\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ee1ea129",
   "metadata": {},
   "source": [
    "As you can hopefully see the new model trained on the synthetic data performs more similarly across the different populations. \n",
    "\n",
    "Why not play with the different synthetic data generation methods and their parameters to see if you can achieve the same improvement in fairness, but with a higher performance? If you need help identifying the right methods then, remember you can list the available plugins with `Plugins().list()` and to learn what they do refer to the [docs](https://synthcity.readthedocs.io/en/latest/generators.html).\n",
    "\n",
    "## 7. Removing bias via causal generation with DECAF\n",
    "\n",
    "DECAF is an inference-time de-biasing method, where the data-generating process is embedded explicitly as a structural causal model in the input layers of the generator, allowing each variable to be reconstructed conditioned on its causal parents. We will use this method to create a different solution to the issue of fairness in this Brazilian COVID-19 dataset.\n",
    "### 7.1 Load the data\n",
    "Lets load the data from file again to make sure we are working with the correct data and nothing has changed. As before we will construct it as a classification problem. But for this excercise we will set the problem up as a classic 2-class fairness task with one class representing the majority ethnic groups (White and Mixed) and one the Minority (Black, East-Asian, and Indigenous)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e3bdf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data from file\n",
    "X = pd.read_csv(f\"../data/Brazil_COVID/covid_normalised_numericalised.csv\")\n",
    "\n",
    "# Set it up as classification task\n",
    "time_horizon = 14\n",
    "X.loc[(X[\"Days_hospital_to_outcome\"] <= time_horizon) & (X[\"is_dead\"] == 1), f\"is_dead_at_time_horizon={time_horizon}\"] = 1\n",
    "X.loc[(X[\"Days_hospital_to_outcome\"] > time_horizon), f\"is_dead_at_time_horizon={time_horizon}\"] = 0\n",
    "X.loc[(X[\"is_dead\"] == 0), f\"is_dead_at_time_horizon={time_horizon}\"] = 0\n",
    "X[f\"is_dead_at_time_horizon={time_horizon}\"] = X[f\"is_dead_at_time_horizon={time_horizon}\"].astype(int)\n",
    "\n",
    "X.drop(columns=[\"is_dead\", \"Days_hospital_to_outcome\"], inplace=True) # drop survival columns as they are not needed for a classification problem\n",
    "\n",
    "# Set up ethnicity as two classes, minority and majority\n",
    "X.loc[(X[\"Ethnicity\"] == 0) | (X[\"Ethnicity\"] == 1), \"Ethnicity\"] = 0 \n",
    "X.loc[(X[\"Ethnicity\"] == 2) | (X[\"Ethnicity\"] == 3) | (X[\"Ethnicity\"] == 4), \"Ethnicity\"] = 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9af15729",
   "metadata": {},
   "source": [
    "Pass the data into the synthcity dataloader. We will just use the `GenericDataloader` here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde5e0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = GenericDataLoader(\n",
    "    X,\n",
    "    target_column=\"is_dead_at_time_horizon=14\",\n",
    "    sensitive_features=[\"Ethnicity\"],\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "display(loader.dataframe())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "153914b3",
   "metadata": {},
   "source": [
    "## 7.2 Load/Create the synthetic data model using DECAF\n",
    "First, we define some useful variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb660f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"fairness.causal_generation\"\n",
    "model = \"decaf\"\n",
    "n_iter = 101\n",
    "count = 6882 # set the count equal to the number of rows in the original dataset\n",
    "random_state=6"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4511f686",
   "metadata": {},
   "source": [
    "Then load the synthetic model from file. If you want to try something a little different you can also fit your own model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a73c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define saved model name\n",
    "save_file = Path(\"saved_models\") / f\"{prefix}_{model}_n_iter={n_iter}_rnd={random_state}.bkp\"\n",
    "\n",
    "# Load from file if available\n",
    "if Path(save_file).exists():\n",
    "    syn_model = serialization.load_from_file(save_file)\n",
    "    dag = syn_model.get_dag(loader.dataframe())\n",
    "    print(f\"DAG before biased edges are removed:\")\n",
    "    display(plot_dag.get_dag_plot(dag))\n",
    "    \n",
    "# create and fit if not available\n",
    "else:\n",
    "    syn_model = decaf_plugin(struct_learning_enabled=True, n_iter=n_iter, random_state=random_state) # Pass struct_learning_enabled=True in order for the syn_model to learn the Dag\n",
    "    dag_before = syn_model.get_dag(loader.dataframe())\n",
    "    syn_model.fit(loader, dag=dag_before, random_state=random_state)\n",
    "    serialization.save_to_file(save_file, syn_model)\n",
    "    print(f\"DAG before biased edges are removed:\")\n",
    "    dag = syn_model.get_dag(loader.dataframe())\n",
    "    display(plot_dag.get_dag_plot(dag))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "328d1e0b",
   "metadata": {},
   "source": [
    "### 7.3 Generate the data\n",
    "We can simply generate the de-biased dataset, by passing the biased edges we wish to remove from the data to `generate`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8f17f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "bias={\"Ethnicity\": [\"is_dead_at_time_horizon=14\"]}\n",
    "decaf_syn_data = syn_model.generate(count, biased_edges=bias, random_state=random_state)\n",
    "display(decaf_syn_data.dataframe())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5eb50c86",
   "metadata": {},
   "source": [
    "### 7.4 DECAF fairness tests\n",
    "\n",
    "We will now check our synthetic data is fairer than the original, real data, by measuring demographic parity. A definition for which can be seen in section 4.1 of the [DECAF paper](https://arxiv.org/abs/2110.12884)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90851f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "demographic_parity_score_gt = fairness_scores.demographic_parity_score(loader)\n",
    "demographic_parity_score_syn = fairness_scores.demographic_parity_score(decaf_syn_data)\n",
    "\n",
    "print(f\"Demographic Parity scores \\nreal data: {demographic_parity_score_gt} | synthetic data: {demographic_parity_score_syn}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "71429207",
   "metadata": {},
   "source": [
    "## 8. Extension\n",
    "Use the code block below as a space to complete the extension exercises below.\n",
    "\n",
    "### 8.1 Plot the DECAF synthetic data to show fairness\n",
    "\n",
    "What is a simple plot we could make to show that the generated data is fair?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f992529",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "765ab416",
   "metadata": {},
   "source": [
    "### 8.2 Our solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7244f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title (i) Plot to show fairness in data generated by DECAF\n",
    "\n",
    "# 2 class ethnicity mapper\n",
    "ethnicity_mapper_2_class = {\n",
    "    0: \"Majority\",\n",
    "    1: \"Minority\"\n",
    "}\n",
    "\n",
    "# Define the model\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    n_estimators=2000,\n",
    "    learning_rate=0.01,\n",
    "    max_depth=5,\n",
    "    subsample=0.8, \n",
    "    colsample_bytree=1, \n",
    "    gamma=1, \n",
    "    objective=\"binary:logistic\",\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "# Load the model trained on the whole dataset\n",
    "saved_model_path = FAIR_RES_PATH / \"fairness_causal_gen_decaf_synthetic_data.json\"\n",
    "xgb_model.load_model(saved_model_path)\n",
    "synth_data_to_predict = decaf_syn_data.dataframe().drop(columns=[\"is_dead_at_time_horizon=14\"])\n",
    "targets_synth_data_to_predict = decaf_syn_data[\"is_dead_at_time_horizon=14\"]\n",
    "\n",
    "# # The saved model was trained with the following code\n",
    "# xgb_model.fit(synth_data_to_predict, targets_synth_data_to_predict)\n",
    "# xgb_model.save_model(saved_model_path)\n",
    "\n",
    "# Get the indices to loop through\n",
    "ethnicity_idxes = decaf_syn_data[\"Ethnicity\"].unique()\n",
    "ethnicity_idxes.sort()\n",
    "\n",
    "predictions = {}\n",
    "for ethnicity_idx in ethnicity_idxes:\n",
    "    synth_data_to_predict_per_ethnicity = synth_data_to_predict.loc[synth_data_to_predict[\"Ethnicity\"] == ethnicity_idx]\n",
    "    # display(synth_data_to_predict)\n",
    "\n",
    "    synthetic_predictions = xgb_model.predict(synth_data_to_predict)\n",
    "\n",
    "    unique, counts = np.unique(synthetic_predictions, return_counts=True)\n",
    "    prediction_counts = {unique[0]: counts[0], unique[1]: counts[1]}\n",
    "    predictions[ethnicity_mapper_2_class[ethnicity_idx]] = prediction_counts\n",
    "\n",
    "prediction_frequency_data = pd.DataFrame(data={\n",
    "    \"Ethnicity\": predictions.keys(),\n",
    "    \"0\": [p_c[0] for p, p_c in predictions.items()],\n",
    "    \"1\": [p_c[1] for p, p_c in predictions.items()],\n",
    "})\n",
    "\n",
    "prediction_frequency_data_m = pd.melt(prediction_frequency_data, id_vars=\"Ethnicity\")\n",
    "prediction_frequency_data_m = prediction_frequency_data_m.rename(\n",
    "    columns={\"variable\": \"is_dead_at_time_horizon\", \"value\": \"Prediction count\"}\n",
    ")\n",
    "\n",
    "\n",
    "sns.catplot(\n",
    "    data=prediction_frequency_data_m,\n",
    "    x=\"Ethnicity\",\n",
    "    y=\"Prediction count\",\n",
    "    hue=\"is_dead_at_time_horizon\",\n",
    "    kind=\"bar\"\n",
    ")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "synth-lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "8b1180d7559eadeaa51f0c23b115f584a6e0cc67e9bc1d662a0e6b39392000a4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
