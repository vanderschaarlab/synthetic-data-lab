{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "97e2d93c",
   "metadata": {},
   "source": [
    "# Case Study 1 - Data Modality\n",
    "\n",
    "```Check if I should use debug method instead of timegan```\n",
    "\n",
    "## The Task\n",
    "Get used to loading datasets with the library and generating synthetic data from them, whatever the modality of the real data.\n",
    "\n",
    "### Imports\n",
    "Lets get the imports out of the way. We import the required standard and 3rd party libraries and relevant Synthcity modules. We can also set the level of logging here, using Synthcity's bespoke logger. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696e0157",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Standard\n",
    "import sys\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "# 3rd party\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# synthcity\n",
    "import synthcity.logger as log\n",
    "from synthcity.plugins import Plugins\n",
    "from synthcity.plugins.core.dataloader import (GenericDataLoader, SurvivalAnalysisDataLoader, TimeSeriesDataLoader,TimeSeriesSurvivalDataLoader)\n",
    "\n",
    "# Configure warnings and logging\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Set the level for the logging\n",
    "# log.add(sink=sys.stderr, level=\"DEBUG\")\n",
    "log.remove()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e9ccba34",
   "metadata": {},
   "source": [
    "# Loading data of different modalities\n",
    "\n",
    "In this notebook we will load different datasets into synthcity and show that data of many different modalities can be used to generate synthetic data using this module.\n",
    "\n",
    "### Static Data\n",
    "Now we will start with the simplest example, static tabular data. For this, we will use the diabetes dataset from sklearn. First, we need to load the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660f2c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "X, y = load_diabetes(return_X_y=True, as_frame=True)\n",
    "X[\"target\"] = y\n",
    "display(X)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a7e79722",
   "metadata": {},
   "source": [
    "Then we pass it to the `GenericDataLoader` object from `synthcity`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51685173",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = GenericDataLoader(\n",
    "    X,\n",
    "    target_column=\"target\",\n",
    "    sensitive_columns=[\"sex\"],\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bc6fb71d",
   "metadata": {},
   "source": [
    "We can print out different methods that are compatible with our data by calling `Plugins().list()` with a relevant list passed to the categories parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7e181c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Plugins(categories=[\"generic\"]).list())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "42a3735d",
   "metadata": {},
   "source": [
    "No need to worry about the code in this next block here, we will go into lots of detail in how to generate synthetic data in the case studies to come. It is here purely to demonstrate that our dataset can be used to generate synthetic data using the synthcity module. We are using the method `marginal_distributions` to generate the synthetic data, which is one of the available debugging methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227a53e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "syn_model = Plugins().get(\"marginal_distributions\")\n",
    "syn_model.fit(loader)\n",
    "syn_model.generate(count=10).dataframe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a66d521f",
   "metadata": {},
   "source": [
    "## Static survival\n",
    "Next lets look at censored data. Censoring is a form of missing data problem in which time to event is not observed for reasons such as termination of study before all recruited subjects have shown the event of interest or the subject has left the study prior to experiencing an event. Censoring is common in survival analysis. For our next example we will load a static survival dataset. Our dataset this time is a veteran lung cancer dataset provided by scikit-survival. \n",
    "\n",
    "First, load the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2186c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sksurv.datasets import load_veterans_lung_cancer\n",
    "\n",
    "data_x, data_y = load_veterans_lung_cancer()\n",
    "data_x[\"status\"], data_x[\"survival_in_days\"] = [record[0] for record in data_y], [record[1] for record in data_y]\n",
    "display(data_x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fef8d763",
   "metadata": {},
   "source": [
    "Pass it to the DataLoader. This time we will use the `SurvivalAnalysisDataLoader`. We need to pass it the data, the name of the column that contains our labels or targets to `target_column` and the the name of the column  containing the time elapsed when the event occurred (the event defined by the target column) to `time_to_event_column`. Calling `info()` on the loader object allows us to see the information about the dataset we have just prepared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db8eea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loader = SurvivalAnalysisDataLoader(\n",
    "    data_x,\n",
    "    target_column=\"status\",\n",
    "    time_to_event_column=\"survival_in_days\",\n",
    ")\n",
    "print(loader.info())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "20fc3730",
   "metadata": {},
   "source": [
    "If we get the `marginal_distributions` plugin again and fit it to the `loader` object, we can then call `generate` to produce the synthetic data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d0ee9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "syn_model = Plugins().get(\"marginal_distributions\")\n",
    "syn_model.fit(loader)\n",
    "syn_model.generate(count=10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "123aec05",
   "metadata": {},
   "source": [
    "### Regular Time Series\n",
    "\n",
    "In this next example we will load up a simple regular time series dataset and show that it is compatible with Synthcity. The temporal data must be passed to the loader as a list of dataframes, where each dataframe in the list refers to a different record and contains all time points for the record. So, there is a small amount of pre-processing to get our data into the right shape. As it is a regular time series we can simply pass a sequential list for each record.\n",
    "\n",
    "The dataset we will use here is the basic motions dataset provided by SKTime. So, we need to import the library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6cb4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.datasets import load_basic_motions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "da2f8600",
   "metadata": {},
   "source": [
    "Load the data and re-format it into a list of dataframes, where each dataframe in the list refers to a different record and contains all time points for the record. We also need the outcomes as a dataframe and the observation times as a list of time steps for each record. As this is a regular time series our time steps can simply be a sequential list of integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26da9e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X, y = load_basic_motions(\n",
    "    split=\"TRAIN\", return_X_y=True, return_type=\"pd-multiindex\"\n",
    ")\n",
    "num_instances = len(set((x[0] for x in X.index)))\n",
    "num_time_steps = len(set((x[1] for x in X.index)))\n",
    "\n",
    "temporal_data = [X.loc[i] for i in range(num_instances)]\n",
    "y = pd.DataFrame(y, columns=[\"label\"])\n",
    "observation_times = [list(range(num_time_steps)) for i in range(num_instances)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "eb4f6c46",
   "metadata": {},
   "source": [
    "Pass the data we just prepared to the DataLoader. Here we will use the `TimeSeriesDataLoader`. Then we will print out the loader info to check everything looks correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9065179e",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = TimeSeriesDataLoader(\n",
    "    temporal_data=temporal_data,\n",
    "    observation_times=observation_times,\n",
    "    outcome=y,\n",
    ")\n",
    "display(loader.dataframe())\n",
    "print(loader.info())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "87b62d94",
   "metadata": {},
   "source": [
    "Now we are ready to produce the synthetic data. We will use the `timegan` plugin to handle the timeseries data. As we don't care about the quality of the dataset here, we just want to check that it is compatible and practice loading datasets, we can pass `n_iter=1` to limit the number of iterations in the generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca58d178",
   "metadata": {},
   "outputs": [],
   "source": [
    "syn_model = Plugins().get(\"timegan\", n_iter=1)\n",
    "syn_model.fit(loader)\n",
    "syn_model.generate(count=10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "46472820",
   "metadata": {},
   "source": [
    "### Irregular Time Series\n",
    "\n",
    "Now lets load an irregular time series dataset and show that that is also compatible with Synthcity. The dataset we will use here is a google stocks dataset provided by the synthcity module itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b0f2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from synthcity.utils.datasets.time_series.google_stocks import GoogleStocksDataloader\n",
    "\n",
    "static_data, temporal_data, observation_times, outcome = GoogleStocksDataloader().load()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9dfdddcd",
   "metadata": {},
   "source": [
    "As the dataset is wrapped by synthcity, it is already provided to us in the correct format, but the requirements are the same as before. The temporal data is a list of dataframes, where each dataframe in the list refers to a different record and contains all time points for the record. The outcomes are all in one dataframe and the observation times are a list of time steps for each record. The main difference here is that the observation times is a list of floats that represent the time between each data point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783b02cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = TimeSeriesDataLoader(\n",
    "    temporal_data=temporal_data,\n",
    "    observation_times=observation_times,\n",
    "    static_data=static_data,\n",
    "    outcome=outcome,\n",
    ")\n",
    "print(loader.info())\n",
    "display(loader.dataframe())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c6f460e7",
   "metadata": {},
   "source": [
    "Exactly as for the regular time series, we can now generate synthetic data, by selecting our time series compatible plugin, then calling `fit()` and `generate()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de443fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "syn_model = Plugins().get(\"timegan\", n_iter=1)\n",
    "syn_model.fit(loader)\n",
    "syn_model.generate(count=5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "64c84cd6",
   "metadata": {},
   "source": [
    "### Composite Irregular Time Series Survival Analysis\n",
    "\n",
    "In this final example we will look at composite data while adding all the other more complex elements we have looked at so far. This next dataset is a composite irregular time series survival analysis dataset. \n",
    "\n",
    "Again this dataset is provided by synthcity, so there is little to do in terms of pre-processing as everything is in the right format to begin with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee82484",
   "metadata": {},
   "outputs": [],
   "source": [
    "from synthcity.utils.datasets.time_series.pbc import PBCDataloader\n",
    "(\n",
    "    static_surv,\n",
    "    temporal_surv,\n",
    "    temporal_surv_horizons,\n",
    "    outcome_surv,\n",
    ") = PBCDataloader().load()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ca102f1b",
   "metadata": {},
   "source": [
    "Even complex datasets such as this are compatible with Synthcity. We can load this data using the `TimeSeriesSurvivalDataLoader`. Then by calling `loader.info()`, we can check the information about the dataset. It contains both one static feature (\"sex\") and 14 temporal features, making it a composite dataset. The `seq_time_id` field shows the irregular time sampling, which we create by passing the values to the `observation_times` parameter of the `TimeSeriesSurvivalDataLoader` object. And finally, we are formulating this data as a survival analysis problem, which is indicated by the presence of a `time_to_event` field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45adb6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "T, E = outcome_surv\n",
    "\n",
    "horizons = [0.25, 0.5, 0.75]\n",
    "time_horizons = np.quantile(T, horizons).tolist()\n",
    "\n",
    "loader = TimeSeriesSurvivalDataLoader(\n",
    "    temporal_data=temporal_surv,\n",
    "    observation_times=temporal_surv_horizons,\n",
    "    static_data=static_surv,\n",
    "    T=T,\n",
    "    E=E,\n",
    "    time_horizons=time_horizons,\n",
    ")\n",
    "\n",
    "print(loader.info())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f3da4696",
   "metadata": {},
   "source": [
    "We can now generate synthetic data, in the way we are now well familiar with. We select our time series compatible plugin, then call `fit()` and `generate()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c673fb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "syn_model = Plugins().get(\"timegan\", n_iter=1)\n",
    "syn_model.fit(loader)\n",
    "syn_model.generate(count=5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "229d9fbe",
   "metadata": {},
   "source": [
    "### Create synthetic datasets\n",
    " 1) Above we have generated data with the debugging method `\"marginal_distributions\"` for tabular data and `timegan` for time series data. Now, using `Plugins().list()` or the documentation find another method that is compatible with some of the datasets to see if you can generate your own snthetic data.\n",
    " \n",
    " 2) Generate synthetic data for another dataset of your choice using the methods described above. You can use any of the other dataset from the sources we have used above: [SKLearn](https://scikit-learn.org/stable/datasets/toy_dataset.html), [SKTime](https://www.sktime.org/en/stable/api_reference/datasets.html), [SKSurv](https://scikit-survival.readthedocs.io/en/stable/api/datasets.html)  or [synthcity](https://github.com/vanderschaarlab/synthcity/tree/main/src/synthcity/utils/datasets) itself."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "synth-lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "8b1180d7559eadeaa51f0c23b115f584a6e0cc67e9bc1d662a0e6b39392000a4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
